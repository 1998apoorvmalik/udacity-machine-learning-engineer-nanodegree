{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "env = gym.make(\"MountainCar-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States: Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n",
      "Actions:  Discrete(3)\n",
      "\n",
      "State Low:  [-1.2  -0.07]\n",
      "state High:  [0.6  0.07]\n",
      "\n",
      "Action space samples:  [1, 2, 0, 2, 0]\n",
      "State space samples:  [[0.015224262, 0.019219099], [0.5720324, -0.054928284], [-0.47429138, -0.010854964]]\n"
     ]
    }
   ],
   "source": [
    "# Print out state space type.\n",
    "print(\"States:\", env.observation_space)\n",
    "# Print out action space type.\n",
    "print(\"Actions: \", env.action_space, end=\"\\n\\n\")\n",
    "\n",
    "# Print out the observation space boundaries.\n",
    "print(\"State Low: \", env.observation_space.low)\n",
    "print(\"state High: \", env.observation_space.high, end=\"\\n\\n\")\n",
    "\n",
    "# Generate some action samples:\n",
    "print(\"Action space samples: \", [env.action_space.sample() for _ in range(5)])\n",
    "# Generate some state samples:\n",
    "print(\"State space samples: \", [list(env.observation_space.sample()) for _ in range(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score =  -200.0\n"
     ]
    }
   ],
   "source": [
    "# Random agent interacting with the environment.\n",
    "env.reset()\n",
    "score = 0\n",
    "while True:\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, info = env.step(action)\n",
    "    score += reward\n",
    "    if done:\n",
    "        break\n",
    "env.close()\n",
    "print(\"Score = \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.collections as mc\n",
    "import matplotlib.pyplot as plt\n",
    "class Preprocess:\n",
    "    def __init__(self, low=[-1.0, -5.0], high=[1.0, 5.0], bins=(10, 10)):\n",
    "        self.low = low\n",
    "        self.high = high\n",
    "        self.bins = bins\n",
    "        self.grid = self.create_uniform_grid()\n",
    "        self.samples_stored = False\n",
    "        \n",
    "    def create_uniform_grid(self):\n",
    "        grid = []\n",
    "        for i, b in enumerate(self.bins):\n",
    "            grid.append(np.linspace(start=self.low[i], stop=self.high[i], num=b, endpoint=False)[1:])\n",
    "        return grid\n",
    "    \n",
    "    def discretize(self, state):\n",
    "        return list(np.digitize(sample, grid) for sample, grid in zip(state, self.grid))\n",
    "    \n",
    "    def store_samples(self, samples, info=False):\n",
    "        self.samples_stored = True\n",
    "        self.samples = samples\n",
    "        self.discretized_samples = np.array([temp.discretize(sample) for sample in samples])\n",
    "        if info:\n",
    "            print(\"\\nSamples:\", repr(self.samples), sep=\"\\n\")\n",
    "            print(\"\\nDiscretized samples:\", repr(self.discretized_samples), sep=\"\\n\")\n",
    "            \n",
    "    def visualize_samples(self):\n",
    "        if self.samples_stored == False:\n",
    "            print(\"Error: Store some samples first\")\n",
    "            return\n",
    "        \n",
    "        low = self.low\n",
    "        high = self.high\n",
    "        grid = self.grid\n",
    "        samples = self.samples\n",
    "        discretized_samples = self.discretized_samples\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        ax.xaxis.set_major_locator(plt.FixedLocator(grid[0]))\n",
    "        ax.yaxis.set_major_locator(plt.FixedLocator(grid[1]))\n",
    "        ax.grid(True)\n",
    "        if low is not None and high is not None:\n",
    "            ax.set_xlim(low[0], high[0])\n",
    "            ax.set_ylim(low[1], high[1])\n",
    "        else:\n",
    "            low = [splits[0] for splits in grid]\n",
    "            high = [splits[-1] for splits in grid]\n",
    "        grid_extended = np.hstack((np.array([low]).T, grid, np.array([high]).T))  # add low and high ends\n",
    "        grid_centers = (grid_extended[:, 1:] + grid_extended[:, :-1]) / 2  # compute center of each grid cell\n",
    "        locs = np.stack(grid_centers[i, discretized_samples[:, i]] for i in range(len(grid))).T  # map discretized samples\n",
    "        ax.plot(samples[:, 0], samples[:, 1], 'o')  # plot original samples\n",
    "        ax.plot(locs[:, 0], locs[:, 1], 's')  # plot discretized samples in mapped locations\n",
    "        ax.add_collection(mc.LineCollection(list(zip(samples, locs)), colors='orange'))  # add a line connecting each original-discretized sample\n",
    "        ax.legend(['original', 'discretized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples:\n",
      "array([[-1.  , -5.  ],\n",
      "       [-0.81, -4.1 ],\n",
      "       [-0.8 , -4.  ],\n",
      "       [-0.5 ,  0.  ],\n",
      "       [ 0.2 , -1.9 ],\n",
      "       [ 0.8 ,  4.  ],\n",
      "       [ 0.81,  4.1 ],\n",
      "       [ 1.  ,  5.  ]])\n",
      "\n",
      "Discretized samples:\n",
      "array([[0, 0],\n",
      "       [0, 0],\n",
      "       [1, 1],\n",
      "       [2, 5],\n",
      "       [5, 3],\n",
      "       [9, 9],\n",
      "       [9, 9],\n",
      "       [9, 9]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/py39-tf-m1/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing the preprocess class.\n",
    "temp = Preprocess()\n",
    "samples = np.array(\n",
    "    [[-1.0 , -5.0],\n",
    "     [-0.81, -4.1],\n",
    "     [-0.8 , -4.0],\n",
    "     [-0.5 ,  0.0],\n",
    "     [ 0.2 , -1.9],\n",
    "     [ 0.8 ,  4.0],\n",
    "     [ 0.81,  4.1],\n",
    "     [ 1.0 ,  5.0]])\n",
    "temp.store_samples(samples, True)\n",
    "temp.visualize_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "class QLearningAgent:\n",
    "    \"\"\"Q-Learning agent that can act on a continuous state space by discretizing it.\"\"\"\n",
    "\n",
    "    def __init__(self, env, bins=(50, 50), alpha=0.02, gamma=0.99,\n",
    "                 epsilon=1.0, epsilon_decay_rate=0.9995, min_epsilon=.01, seed=505):\n",
    "        \"\"\"Initialize variables, create grid for discretization.\"\"\"\n",
    "        \n",
    "        # Environment info\n",
    "        self.bins = bins\n",
    "        self.env = env\n",
    "        self.state_grid = self.create_uniform_grid()\n",
    "        self.state_size = tuple(len(splits) + 1 for splits in self.state_grid)  # n-dimensional state space\n",
    "        self.action_size = self.env.action_space.n  # 1-dimensional discrete action space\n",
    "        self.seed = np.random.seed(seed)\n",
    "        self.samples_stored = False\n",
    "        self.training_done = False\n",
    "        print(\"Environment:\", self.env)\n",
    "        print(\"State space size:\", self.state_size)\n",
    "        print(\"Action space size:\", self.action_size)\n",
    "        \n",
    "        # Learning parameters\n",
    "        self.alpha = alpha  # learning rate\n",
    "        self.gamma = gamma  # discount factor\n",
    "        self.epsilon = self.initial_epsilon = epsilon  # initial exploration rate\n",
    "        self.epsilon_decay_rate = epsilon_decay_rate # how quickly should we decrease epsilon\n",
    "        self.min_epsilon = min_epsilon\n",
    "        \n",
    "        # Create Q-table\n",
    "        self.q_table = np.zeros(shape=(self.state_size + (self.action_size,)))\n",
    "        print(\"Q table size:\", self.q_table.shape)\n",
    "    \n",
    "    def create_uniform_grid(self):\n",
    "        grid = []\n",
    "        for i, b in enumerate(self.bins):\n",
    "            grid.append(np.linspace(start=self.env.observation_space.low[i], \n",
    "                                    stop=self.env.observation_space.high[i], num=b, endpoint=False)[1:])\n",
    "        return grid\n",
    "    \n",
    "    def discretize(self, state):\n",
    "        return list(np.digitize(sample, grid) for sample, grid in zip(state, self.state_grid))\n",
    "    \n",
    "    def store_samples(self, samples, info=False):\n",
    "        self.samples_stored = True\n",
    "        self.samples = samples\n",
    "        self.discretized_samples = np.array([temp.discretize(sample) for sample in samples])\n",
    "        if info:\n",
    "            print(\"\\nSamples:\", repr(self.samples), sep=\"\\n\")\n",
    "            print(\"\\nDiscretized samples:\", repr(self.discretized_samples), sep=\"\\n\")\n",
    "            \n",
    "    def visualize_samples(self):\n",
    "        if self.samples_stored == False:\n",
    "            print(\"Error: Store some samples first\")\n",
    "            return\n",
    "        \n",
    "        low = self.low\n",
    "        high = self.high\n",
    "        grid = self.grid\n",
    "        samples = self.samples\n",
    "        discretized_samples = self.discretized_samples\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        ax.xaxis.set_major_locator(plt.FixedLocator(grid[0]))\n",
    "        ax.yaxis.set_major_locator(plt.FixedLocator(grid[1]))\n",
    "        ax.grid(True)\n",
    "        if low is not None and high is not None:\n",
    "            ax.set_xlim(low[0], high[0])\n",
    "            ax.set_ylim(low[1], high[1])\n",
    "        else:\n",
    "            low = [splits[0] for splits in grid]\n",
    "            high = [splits[-1] for splits in grid]\n",
    "        grid_extended = np.hstack((np.array([low]).T, grid, np.array([high]).T))  # add low and high ends\n",
    "        grid_centers = (grid_extended[:, 1:] + grid_extended[:, :-1]) / 2  # compute center of each grid cell\n",
    "        locs = np.stack(grid_centers[i, discretized_samples[:, i]] for i in range(len(grid))).T  # map discretized samples\n",
    "        ax.plot(samples[:, 0], samples[:, 1], 'o')  # plot original samples\n",
    "        ax.plot(locs[:, 0], locs[:, 1], 's')  # plot discretized samples in mapped locations\n",
    "        ax.add_collection(mc.LineCollection(list(zip(samples, locs)), colors='orange'))  # add a line connecting each original-discretized sample\n",
    "        ax.legend(['original', 'discretized'])\n",
    "\n",
    "    def preprocess_state(self, state):\n",
    "        \"\"\"Map a continuous state to its discretized representation.\"\"\"\n",
    "        # TODO: Implement this\n",
    "        return tuple(self.discretize(state))\n",
    "\n",
    "    def reset_episode(self, state):\n",
    "        \"\"\"Reset variables for a new episode.\"\"\"\n",
    "        # Gradually decrease exploration rate\n",
    "        self.epsilon *= self.epsilon_decay_rate\n",
    "        self.epsilon = max(self.epsilon, self.min_epsilon)\n",
    "\n",
    "        # Decide initial action\n",
    "        self.last_state = self.preprocess_state(state)\n",
    "        self.last_action = np.argmax(self.q_table[self.last_state])\n",
    "        return self.last_action\n",
    "    \n",
    "    def reset_exploration(self, epsilon=None):\n",
    "        \"\"\"Reset exploration rate used when training.\"\"\"\n",
    "        self.epsilon = epsilon if epsilon is not None else self.initial_epsilon\n",
    "        \n",
    "    def plot_scores(self, rolling_window=100):\n",
    "        \"\"\"Plot scores and optional rolling mean using specified window.\"\"\"\n",
    "        if self.training_done == False:\n",
    "            print(\"Error: Training not done\")\n",
    "        scores = self.scores\n",
    "        plt.plot(scores); plt.title(\"Scores\");\n",
    "        rolling_mean = pd.Series(scores).rolling(rolling_window).mean()\n",
    "        plt.plot(rolling_mean);\n",
    "    \n",
    "    def plot_q_table(self):\n",
    "        \"\"\"Visualize max Q-value for each state and corresponding action.\"\"\"\n",
    "        q_table = self.q_table\n",
    "        q_image = np.max(q_table, axis=2)       # max Q-value for each state\n",
    "        q_actions = np.argmax(q_table, axis=2)  # best action for each state\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        cax = ax.imshow(q_image, cmap='jet');\n",
    "        cbar = fig.colorbar(cax)\n",
    "        for x in range(q_image.shape[0]):\n",
    "            for y in range(q_image.shape[1]):\n",
    "                ax.text(x, y, q_actions[x, y], color='white',\n",
    "                        horizontalalignment='center', verticalalignment='center')\n",
    "        ax.grid(False)\n",
    "        ax.set_title(\"Q-table, size: {}\".format(q_table.shape))\n",
    "        ax.set_xlabel('position')\n",
    "        ax.set_ylabel('velocity')\n",
    "\n",
    "    def act(self, state, reward=None, done=None, mode='train', time_delay=0.01):\n",
    "        \"\"\"Pick next action and update internal Q table (when mode != 'test').\"\"\"\n",
    "        state = self.preprocess_state(state)\n",
    "        if mode == 'test':\n",
    "            # Test mode: Simply produce an action\n",
    "            action = np.argmax(self.q_table[state])\n",
    "            time.sleep(time_delay)\n",
    "        else:\n",
    "            # Train mode (default): Update Q table, pick next action\n",
    "            # Note: We update the Q table entry for the *last* (state, action) pair with current state, reward\n",
    "            self.q_table[self.last_state + (self.last_action,)] += self.alpha * \\\n",
    "                (reward + self.gamma * max(self.q_table[state]) - self.q_table[self.last_state + (self.last_action,)])\n",
    "\n",
    "            # Exploration vs. exploitation\n",
    "            do_exploration = np.random.uniform(0, 1) < self.epsilon\n",
    "            if do_exploration:\n",
    "                # Pick a random action\n",
    "                action = np.random.randint(0, self.action_size)\n",
    "            else:\n",
    "                # Pick the best action from Q table\n",
    "                action = np.argmax(self.q_table[state])\n",
    "\n",
    "        # Roll over current state, action for next step\n",
    "        self.last_state = state\n",
    "        self.last_action = action\n",
    "        return action\n",
    "    \n",
    "    def run(self, num_episodes=20000, mode=\"train\", time_delay=0.01):\n",
    "        \"\"\"Run agent in given reinforcement learning environment and return scores.\"\"\"\n",
    "        scores = []\n",
    "        max_avg_score = -np.inf\n",
    "        for i_episode in range(1, num_episodes+1):\n",
    "            # Initialize episode\n",
    "            state = self.env.reset()\n",
    "            action = self.reset_episode(state)\n",
    "            total_reward = 0\n",
    "            done = False\n",
    "\n",
    "            # Roll out steps until done\n",
    "            while not done:\n",
    "                if mode=='test':\n",
    "                    env.render()\n",
    "                state, reward, done, info = self.env.step(action)\n",
    "                total_reward += reward\n",
    "                action = self.act(state, reward, done, mode, time_delay)\n",
    "            \n",
    "            # Save final score\n",
    "            scores.append(total_reward)\n",
    "\n",
    "            # Print episode stats\n",
    "            if mode == 'train':\n",
    "                self.training_done = True\n",
    "                if len(scores) > 100:\n",
    "                    avg_score = np.mean(scores[-100:])\n",
    "                    if avg_score > max_avg_score:\n",
    "                        max_avg_score = avg_score\n",
    "                if i_episode % 100 == 0:\n",
    "                    print(\"\\rEpisode {}/{} | Max Average Score: {}\".format(i_episode, num_episodes, max_avg_score), end=\"\")\n",
    "                    sys.stdout.flush()\n",
    "        \n",
    "        # Close rendering\n",
    "        env.close()\n",
    "        if mode == \"test\":\n",
    "            print(\"Score: \", np.mean(scores))\n",
    "        else:\n",
    "            self.scores = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment: <TimeLimit<MountainCarEnv<MountainCar-v0>>>\n",
      "State space size: (20, 20)\n",
      "Action space size: 3\n",
      "Q table size: (20, 20, 3)\n"
     ]
    }
   ],
   "source": [
    "# Creating the agent\n",
    "agent = QLearningAgent(env, bins = (20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1800/100000 | Max Average Score: -200.0"
     ]
    }
   ],
   "source": [
    "# Training the agent\n",
    "agent.run(num_episodes = 100000, mode=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the scores\n",
    "agent.plot_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Q-Table\n",
    "agent.plot_q_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the agent\n",
    "agent.run(num_episodes=1, mode=\"test\", time_delay = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('py39-tf-m1': conda)",
   "language": "python",
   "name": "python397jvsc74a57bd0dde3562a707dd5c908cff731c5d458cabc735e0a8d718c859c4a294627fec5bb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
