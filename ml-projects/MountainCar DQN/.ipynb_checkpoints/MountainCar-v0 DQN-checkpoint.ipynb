{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "env = gym.make(\"MountainCar-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States: Box(2,)\n",
      "Actions:  Discrete(3)\n",
      "\n",
      "State Low:  [-1.2  -0.07]\n",
      "state High:  [0.6  0.07]\n",
      "\n",
      "Action space samples:  [0, 2, 2, 2, 2]\n",
      "State space samples:  [[-1.0377363, 0.00786727], [-0.96824354, 0.0067375037], [-0.8295597, -0.05741305]]\n"
     ]
    }
   ],
   "source": [
    "# Print out state space type.\n",
    "print(\"States:\", env.observation_space)\n",
    "# Print out action space type.\n",
    "print(\"Actions: \", env.action_space, end=\"\\n\\n\")\n",
    "\n",
    "# Print out the observation space boundaries.\n",
    "print(\"State Low: \", env.observation_space.low)\n",
    "print(\"state High: \", env.observation_space.high, end=\"\\n\\n\")\n",
    "\n",
    "# Generate some action samples:\n",
    "print(\"Action space samples: \", [env.action_space.sample() for _ in range(5)])\n",
    "# Generate some state samples:\n",
    "print(\"State space samples: \", [list(env.observation_space.sample()) for _ in range(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score =  -200.0\n"
     ]
    }
   ],
   "source": [
    "# Random agent interacting with the environment.\n",
    "env.reset()\n",
    "score = 0\n",
    "while True:\n",
    "    env.render()\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, info = env.step(action)\n",
    "    score += reward\n",
    "    if done:\n",
    "        break\n",
    "env.close()\n",
    "print(\"Score = \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.collections as mc\n",
    "import matplotlib.pyplot as plt\n",
    "class Preprocess:\n",
    "    def __init__(self, low=[-1.0, -5.0], high=[1.0, 5.0], bins=(10, 10)):\n",
    "        self.low = low\n",
    "        self.high = high\n",
    "        self.bins = bins\n",
    "        self.grid = self.create_uniform_grid()\n",
    "        self.samples_stored = False\n",
    "        \n",
    "    def create_uniform_grid(self):\n",
    "        grid = []\n",
    "        for i, b in enumerate(self.bins):\n",
    "            grid.append(np.linspace(start=self.low[i], stop=self.high[i], num=b, endpoint=False)[1:])\n",
    "        return grid\n",
    "    \n",
    "    def discretize(self, state):\n",
    "        return list(np.digitize(sample, grid) for sample, grid in zip(state, self.grid))\n",
    "    \n",
    "    def store_samples(self, samples, info=False):\n",
    "        self.samples_stored = True\n",
    "        self.samples = samples\n",
    "        self.discretized_samples = np.array([temp.discretize(sample) for sample in samples])\n",
    "        if info:\n",
    "            print(\"\\nSamples:\", repr(self.samples), sep=\"\\n\")\n",
    "            print(\"\\nDiscretized samples:\", repr(self.discretized_samples), sep=\"\\n\")\n",
    "            \n",
    "    def visualize_samples(self):\n",
    "        if self.samples_stored == False:\n",
    "            print(\"Error: Store some samples first\")\n",
    "            return\n",
    "        \n",
    "        low = self.low\n",
    "        high = self.high\n",
    "        grid = self.grid\n",
    "        samples = self.samples\n",
    "        discretized_samples = self.discretized_samples\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        ax.xaxis.set_major_locator(plt.FixedLocator(grid[0]))\n",
    "        ax.yaxis.set_major_locator(plt.FixedLocator(grid[1]))\n",
    "        ax.grid(True)\n",
    "        if low is not None and high is not None:\n",
    "            ax.set_xlim(low[0], high[0])\n",
    "            ax.set_ylim(low[1], high[1])\n",
    "        else:\n",
    "            low = [splits[0] for splits in grid]\n",
    "            high = [splits[-1] for splits in grid]\n",
    "        grid_extended = np.hstack((np.array([low]).T, grid, np.array([high]).T))  # add low and high ends\n",
    "        grid_centers = (grid_extended[:, 1:] + grid_extended[:, :-1]) / 2  # compute center of each grid cell\n",
    "        locs = np.stack(grid_centers[i, discretized_samples[:, i]] for i in range(len(grid))).T  # map discretized samples\n",
    "        ax.plot(samples[:, 0], samples[:, 1], 'o')  # plot original samples\n",
    "        ax.plot(locs[:, 0], locs[:, 1], 's')  # plot discretized samples in mapped locations\n",
    "        ax.add_collection(mc.LineCollection(list(zip(samples, locs)), colors='orange'))  # add a line connecting each original-discretized sample\n",
    "        ax.legend(['original', 'discretized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples:\n",
      "array([[-1.  , -5.  ],\n",
      "       [-0.81, -4.1 ],\n",
      "       [-0.8 , -4.  ],\n",
      "       [-0.5 ,  0.  ],\n",
      "       [ 0.2 , -1.9 ],\n",
      "       [ 0.8 ,  4.  ],\n",
      "       [ 0.81,  4.1 ],\n",
      "       [ 1.  ,  5.  ]])\n",
      "\n",
      "Discretized samples:\n",
      "array([[0, 0],\n",
      "       [0, 0],\n",
      "       [1, 1],\n",
      "       [2, 5],\n",
      "       [5, 3],\n",
      "       [9, 9],\n",
      "       [9, 9],\n",
      "       [9, 9]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apoorvmalik/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:50: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing the preprocess class.\n",
    "temp = Preprocess()\n",
    "samples = np.array(\n",
    "    [[-1.0 , -5.0],\n",
    "     [-0.81, -4.1],\n",
    "     [-0.8 , -4.0],\n",
    "     [-0.5 ,  0.0],\n",
    "     [ 0.2 , -1.9],\n",
    "     [ 0.8 ,  4.0],\n",
    "     [ 0.81,  4.1],\n",
    "     [ 1.0 ,  5.0]])\n",
    "temp.store_samples(samples, True)\n",
    "temp.visualize_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.state_size = env.observation_space.shape[0]\n",
    "        self.action_size = env.action_space.n\n",
    "        self.replay_memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95    # discount rate\n",
    "        self.epsilon = 1.0  # exploration rate\n",
    "        self.min_epsilon = 0.01\n",
    "        self.epsilon_decay_rate = 0.995\n",
    "        self.learning_rate = 0.001\n",
    "        self.bins = (20, 20)\n",
    "        self.minibatch_size = 32\n",
    "        self.min_replay_memory_size = 500\n",
    "        self.target_update_frequency = 10\n",
    "        self.target_update_counter = 0\n",
    "        self.training_done = False\n",
    "        self.grid = self.create_uniform_grid()\n",
    "        \n",
    "        # main model  # gets trained every step\n",
    "        self.model = self.build_model()\n",
    "\n",
    "        # Target model this is what we .predict against every step\n",
    "        self.target_model = self.build_model()\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "    \n",
    "    def build_model(self):\n",
    "        # Neural Net for Deep-Q learning Model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(64, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=0.001))\n",
    "        model.summary()\n",
    "        return model\n",
    "    \n",
    "    def reset_episode(self, state):\n",
    "        \"\"\"Reset variables for a new episode.\"\"\"\n",
    "        # Gradually decrease exploration rate\n",
    "        self.epsilon *= self.epsilon_decay_rate\n",
    "        self.epsilon = max(self.epsilon, self.min_epsilon)\n",
    "\n",
    "        # Decide initial action\n",
    "        self.last_state = self.preprocess_state(state)\n",
    "        self.last_action = np.argmax(self.model.predict(self.last_state))\n",
    "        return self.last_action\n",
    "    \n",
    "    def create_uniform_grid(self):\n",
    "        grid = []\n",
    "        for i, b in enumerate(self.bins):\n",
    "            grid.append(np.linspace(start=self.env.observation_space.low[i], \n",
    "                                    stop=self.env.observation_space.high[i], num=b, endpoint=False)[1:])\n",
    "        return grid\n",
    "    \n",
    "    def reset_exploration(self, epsilon=None):\n",
    "        \"\"\"Reset exploration rate used when training.\"\"\"\n",
    "        self.epsilon = epsilon if epsilon is not None else self.initial_epsilon\n",
    "        \n",
    "    def plot_scores(self, rolling_window=100):\n",
    "        \"\"\"Plot scores and optional rolling mean using specified window.\"\"\"\n",
    "        if self.training_done == False:\n",
    "            print(\"Error: Training not done\")\n",
    "        scores = self.scores\n",
    "        plt.plot(scores); plt.title(\"Scores\");\n",
    "        rolling_mean = pd.Series(scores).rolling(rolling_window).mean()\n",
    "        plt.plot(rolling_mean);\n",
    "    \n",
    "    def discretize(self, state):\n",
    "        return list(np.digitize(sample, grid) for sample, grid in zip(state, self.grid))\n",
    "    \n",
    "    def preprocess_state(self, state):\n",
    "        state = np.reshape(self.discretize(state), [1, self.env.observation_space.shape[0]])\n",
    "        return state\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.replay_memory.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def act(self, state, reward=None, done=None, mode='train', time_delay=0.01):\n",
    "        \"\"\"Pick next action and update weights of the neural network (when mode != 'test').\"\"\"\n",
    "        state = self.preprocess_state(state)\n",
    "        if mode == 'test':\n",
    "            # Test mode: Simply produce an action\n",
    "            action = np.argmax(self.model.predict(state))\n",
    "            time.sleep(time_delay)\n",
    "        else:\n",
    "            # Exploration vs. exploitation\n",
    "            do_exploration = np.random.uniform(0, 1) < self.epsilon\n",
    "            if do_exploration:\n",
    "                # Pick a random action\n",
    "                action = np.random.randint(0, self.action_size)\n",
    "            else:\n",
    "                # Pick the best action from Q table\n",
    "                action = np.argmax(self.model.predict(state))\n",
    "            \n",
    "            # Store the experience in replay memory\n",
    "            self.remember(self.last_state[0], self.last_action, reward, state[0], done)\n",
    "            \n",
    "            if len(self.replay_memory) >= self.min_replay_memory_size:\n",
    "                minibatch = random.sample(self.replay_memory, self.minibatch_size)\n",
    "                self.replay(minibatch, done)\n",
    "\n",
    "        # Roll over current state, action for next step\n",
    "        self.last_state = state\n",
    "        self.last_action = action\n",
    "        return action\n",
    "    \n",
    "    def run(self, num_episodes=20000, mode=\"train\", time_delay=0.01, score_threshold=None):\n",
    "        \"\"\"Run agent in given reinforcement learning environment and return scores.\"\"\"\n",
    "        scores = []\n",
    "        max_avg_score = -np.inf\n",
    "        for i_episode in range(1, num_episodes+1):\n",
    "            # Initialize episode\n",
    "            state = self.env.reset()\n",
    "            action = self.reset_episode(state)\n",
    "            total_reward = 0\n",
    "            done = False\n",
    "\n",
    "            # Roll out steps until done\n",
    "            while not done:\n",
    "                if mode=='test':\n",
    "                    env.render()\n",
    "                state, reward, done, info = self.env.step(action)\n",
    "                total_reward += reward\n",
    "                action = self.act(state, reward, done, mode, time_delay)\n",
    "                env.render()\n",
    "            # Save final score\n",
    "            scores.append(total_reward)\n",
    "            # Print episode stats\n",
    "            if mode == 'train':\n",
    "                self.training_done = True\n",
    "                if len(scores) > 100:\n",
    "                    avg_score = np.mean(scores[-100:])\n",
    "                    if avg_score > max_avg_score:\n",
    "                        max_avg_score = avg_score\n",
    "                if i_episode % 100 == 0:\n",
    "                    print(\"\\rEpisode {}/{} | Max Average Score: {}\".format(i_episode, num_episodes, max_avg_score), end=\"\")\n",
    "                    sys.stdout.flush()\n",
    "            \n",
    "            # Terminating loop if the agent achieves reward threshold\n",
    "            if score_threshold != None and max_avg_score > score_threshold:\n",
    "                print(\"\\nEnvironment solved after {} episodes, epsilon = {}\".format(i_episode, epsilon))\n",
    "                break\n",
    "        \n",
    "        # Close rendering\n",
    "        env.close()\n",
    "        self.model.save_weights('my_model_weights.h5')\n",
    "        if mode == \"test\":\n",
    "            print(\"Score: \", np.mean(scores))\n",
    "        else:\n",
    "            self.scores = scores\n",
    "    \n",
    "    def replay(self, minibatch, terminal_state):\n",
    "        # Get current states from minibatch, then query NN model for Q values\n",
    "        current_states = np.array([transition[0] for transition in minibatch])\n",
    "        current_qs_list = self.model.predict(current_states)\n",
    "\n",
    "        # Get future states from minibatch, then query NN model for Q values\n",
    "        # When using target network, query it, otherwise main network should be queried\n",
    "        new_current_states = np.array([transition[3] for transition in minibatch])\n",
    "        future_qs_list = self.target_model.predict(new_current_states)\n",
    "        \n",
    "        X = []\n",
    "        y = []\n",
    "\n",
    "        # Now we need to enumerate our batches\n",
    "        for index, (current_state, action, reward, new_current_state, done) in enumerate(minibatch):\n",
    "\n",
    "            # If not a terminal state, get new q from future states, otherwise set it to 0\n",
    "            # almost like with Q Learning, but we use just part of equation here\n",
    "            if not done:\n",
    "                max_future_q = np.max(future_qs_list[index])\n",
    "                new_q = reward + self.gamma * max_future_q\n",
    "            else:\n",
    "                new_q = reward\n",
    "\n",
    "            # Update Q value for given state\n",
    "            current_qs = current_qs_list[index]\n",
    "            current_qs[action] = new_q\n",
    "\n",
    "            # And append to our training data\n",
    "            X.append(current_state)\n",
    "            y.append(current_qs)\n",
    "\n",
    "        # Fit on all samples as one batch, log only on terminal state\n",
    "        self.model.fit(np.array(X), np.array(y), batch_size=self.minibatch_size, verbose=0, shuffle=False)\n",
    "        \n",
    "        if terminal_state:\n",
    "            self.target_update_counter += 1\n",
    "\n",
    "        # If counter reaches set value, update target network with weights of main network\n",
    "        if self.target_update_counter > self.target_update_frequency:\n",
    "            self.target_model.set_weights(self.model.get_weights())\n",
    "            self.target_update_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/apoorvmalik/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 24)                72        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 75        \n",
      "=================================================================\n",
      "Total params: 747\n",
      "Trainable params: 747\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 24)                72        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 75        \n",
      "=================================================================\n",
      "Total params: 747\n",
      "Trainable params: 747\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "agent = DQNAgent(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### agent.run(num_episodes = 10000, mode = 'train', score_threshold = -110) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.plot_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
